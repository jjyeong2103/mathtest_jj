from model import *
from transformers import AutoTokenizer
from transformers import BertTokenizer
import streamlit as st
import torch
import numpy as np

st.title("ìë™ ì±„ì  ëª¨ë¸ ê¸°ë°˜ ìë™ í”¼ë“œë°±")

st.markdown("---")
st.write("**íŒ€ì›** : âœ¨ìˆ˜í•™êµìœ¡ê³¼ ê¹€ëª…ì‹, ê¹€ì¬í›ˆ, ê¹€ì§€ì˜, ì‹ ì¸ì„­, ìœ¤ì˜ˆë¦°, ì •ìœ ì§„âœ¨")
st.markdown("---")

import streamlit as st
import time
with st.spinner(text='ì˜¤ëŠ˜ ìˆ˜ì—… ì¦ê²ê²Œ ë“¤ì—ˆë‚˜ìš”? ì´ì œ ì—¬ëŸ¬ë¶„ë“¤ì´ ì–¼ë§ˆë‚˜ ê³µë¶€ë¥¼ ì—´ì‹¬íˆ í–ˆëŠ”ì§€ ì•Œì•„ë³´ë„ë¡ í•´ìš”!'):
    time.sleep(10)
    st.success('ì, ì‹œì‘í•´ë³¼ê¹Œìš”?')


# ë¬¸í•­1-1

st.subheader("ë¬¸í•­1-1")
st.markdown("$$ a^{2} \\times a^{5} = $$")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_1')

# ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_1 = "1-1_rnn_sp_60"  # ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
# ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 60  # vocab size
emb = 16  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu"  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
# output_d ì„¤ì •
output_d_1_1 = 1  # ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

model_1_1 = RNNModel(output_d_1_1, c)  # RNNModel ì“°ëŠ”ê²½ìš°
# model = LSTMModel(output_d, c) #LSTMModel ì“°ëŠ”ê²½ìš°
# model = ATTModel(output_d, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_1.load_state_dict(torch.load("./save/"+model_name_1_1+".pt"))

# ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_1 = AutoTokenizer.from_pretrained("./save/"+model_name_1_1)  # sp tokenizer ì“°ëŠ” ê²½ìš°
# tokenizer = BertTokenizer.from_pretrained("./save/"+model_name+"-vocab.txt") #bw tokenizer ì“°ëŠ”ê²½ìš°

enc = tokenizer_1_1(response)["input_ids"]  # sp tokenizer
# enc = tokenizer.encode(response) #bw tokenizer
l = len(enc)
if l < max_len:
    pad = (max_len - l) * [0] + enc
else:
    pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1, max_len)
y = model_1_1(pad_ten)
label_1_1 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button1_1_1_1'):
    
    # outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
   st.write(response)
   if label_1_1 == 1:
       st.success('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")
   else:
       st.info('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")

if st.button('â“íŒíŠ¸ ë³´ê¸°', key='button1_1_1_2'):
    st.write('ë°‘ì´ aë¡œ ê°™ì•„ìš”!')



st.markdown("---")
# ë¬¸í•­1-2

st.subheader("ë¬¸í•­1-2")
st.markdown("$$ (x^{4})^{3} \\times (x^{2})^{5} = $$")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_2')

# ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_2 = "1-2_att_sp_60"  # ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
# ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 60  # vocab size
emb = 16  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu"  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
# output_d ì„¤ì •
output_d_1_2 = 2  # ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

# model = RNNModel(output_d, c)  # RNNModel ì“°ëŠ”ê²½ìš°
# model = LSTMModel(output_d, c) #LSTMModel ì“°ëŠ”ê²½ìš°
model_1_2 = ATTModel(output_d_1_2, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_2.load_state_dict(torch.load("./save/"+model_name_1_2+".pt"))

# ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_2 = AutoTokenizer.from_pretrained("./save/"+model_name_1_2)  # sp tokenizer ì“°ëŠ” ê²½ìš°
# tokenizer = BertTokenizer.from_pretrained("./save/"+model_name+"-vocab.txt") #bw tokenizer ì“°ëŠ”ê²½ìš°

enc = tokenizer_1_2(response)["input_ids"]  # sp tokenizer
# enc = tokenizer.encode(response) #bw tokenizer
l = len(enc)
if l < max_len:
    pad = (max_len - l) * [0] + enc
else:
    pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1, max_len)
y = model_1_2(pad_ten)
label_1_2 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button1_1_2_1'):
    
    # outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
   st.write(response)
   if len(label_1_2) >= 2:
       if label_1_2[0] == 1 and label_1_2[1] == 1 :
           st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")
       #elif label_1_2[0] == 1 and label_1_2[1] == 0:
            #st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
       #elif label_1_2[0] == 0 and label_1_2[1] == 1:
            #st.success('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")     
       else:
            st.info('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")


if st.button('â“íŒíŠ¸ ë³´ê¸°', key='button1_1_2_2'):
    st.write('ê´„í˜¸ë¥¼ ë¨¼ì € ì •ë¦¬í•˜ì„¸ìš”!')



st.markdown("---")
# ë¬¸í•­1-3

st.subheader("ë¬¸í•­1-3")
st.markdown("$$ b^{3} \\div b^{6} = $$")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_3')

# ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_3 = "1-3_att_sp_62"  # ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
# ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 62  # vocab size
emb = 16  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu"  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
# output_d ì„¤ì •
output_d_1_3 = 1  # ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

# model = RNNModel(output_d, c)  # RNNModel ì“°ëŠ”ê²½ìš°
# model = LSTMModel(output_d, c) #LSTMModel ì“°ëŠ”ê²½ìš°
model_1_3 = ATTModel(output_d_1_3, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_3.load_state_dict(torch.load("./save/"+model_name_1_3+".pt"))

# ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_3 = AutoTokenizer.from_pretrained("./save/"+model_name_1_3)  # sp tokenizer ì“°ëŠ” ê²½ìš°
# tokenizer = BertTokenizer.from_pretrained("./save/"+model_name+"-vocab.txt") #bw tokenizer ì“°ëŠ”ê²½ìš°

enc = tokenizer_1_3(response)["input_ids"]  # sp tokenizer
# enc = tokenizer.encode(response) #bw tokenizer
l = len(enc)
if l < max_len:
    pad = (max_len - l) * [0] + enc
else:
    pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1, max_len)
y = model_1_3(pad_ten)
label_1_3 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button1_1_3_1'):
    
    # outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
   st.write(response)
   if label_1_3 == 1:
       st.success('ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ3ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")   
   else:
            st.info('ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆì„ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")

if st.button('â“íŒíŠ¸ ë³´ê¸°', key='button1_1_3_2'):
    st.write('ë°‘ì´ bë¡œ ê°™ì•„ìš”!')


st.markdown("---")
# ë¬¸í•­1-4

st.subheader("ë¬¸í•­1-4")
st.markdown("$$ a^{12} \\div a^{3} \\div a^{9} = $$")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_4')

# ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_4 = "1-4_att_sp_74"  # ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
# ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 74  # vocab size
emb = 16  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu"  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
# output_d ì„¤ì •
output_d_1_4 = 2  # ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

# model = RNNModel(output_d, c)  # RNNModel ì“°ëŠ”ê²½ìš°
# model = LSTMModel(output_d, c) #LSTMModel ì“°ëŠ”ê²½ìš°
model_1_4 = ATTModel(output_d_1_4, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_4.load_state_dict(torch.load("./save/"+model_name_1_4+".pt"))

# ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_4 = AutoTokenizer.from_pretrained("./save/"+model_name_1_4)  # sp tokenizer ì“°ëŠ” ê²½ìš°
# tokenizer = BertTokenizer.from_pretrained("./save/"+model_name+"-vocab.txt") #bw tokenizer ì“°ëŠ”ê²½ìš°

enc = tokenizer_1_4(response)["input_ids"]  # sp tokenizer
# enc = tokenizer.encode(response) #bw tokenizer
l = len(enc)
if l < max_len:
    pad = (max_len - l) * [0] + enc
else:
    pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1, max_len)
y = model_1_4(pad_ten)
label_1_4 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button1_1_4_1'):
    
    # outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
   st.write(response)
   if len(label_1_4) >= 2:
       if label_1_4[0] == 1 and label_1_4[1] == 1 :
           st.success('ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ1, ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ2ë¥¼ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")
       #elif label_1_2[0] == 1 and label_1_2[1] == 0:
            #st.success('ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ1ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ2ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
       #elif label_1_2[0] == 0 and label_1_2[1] == 1:
            #st.success('ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ2ë¥¼ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ1ì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")     
       else:
            st.info('ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ1, ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ2ë¥¼ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")


if st.button('â“íŒíŠ¸ ë³´ê¸°', key='button1_1_4_2'):
    st.write('ì§€ìˆ˜ì˜ ëŒ€ì†Œë¥¼ ì²´í¬í•˜ì„¸ìš”!')


st.markdown("---")
# ë¬¸í•­1-5

st.subheader("ë¬¸í•­1-5")
st.markdown("$$ (2a^{4})^{3} = $$")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_5')

# ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_5 = "1-5_att_sp_74"  # ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
# ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 74  # vocab size
emb = 16  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu"  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
# output_d ì„¤ì •
output_d_1_5 = 2  # ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

# model = RNNModel(output_d, c)  # RNNModel ì“°ëŠ”ê²½ìš°
# model = LSTMModel(output_d, c) #LSTMModel ì“°ëŠ”ê²½ìš°
model_1_5 = ATTModel(output_d_1_5, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_5.load_state_dict(torch.load("./save/"+model_name_1_5+".pt"))

# ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_5 = AutoTokenizer.from_pretrained("./save/"+model_name_1_5)  # sp tokenizer ì“°ëŠ” ê²½ìš°
# tokenizer = BertTokenizer.from_pretrained("./save/"+model_name+"-vocab.txt") #bw tokenizer ì“°ëŠ”ê²½ìš°

enc = tokenizer_1_5(response)["input_ids"]  # sp tokenizer
# enc = tokenizer.encode(response) #bw tokenizer
l = len(enc)
if l < max_len:
    pad = (max_len - l) * [0] + enc
else:
    pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1, max_len)
y = model_1_5(pad_ten)
label_1_5 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button1_1_5_1'):
    
    # outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
   st.write(response)
   if len(label_1_5) >= 2:
       if label_1_5[0] == 1 and label_1_5[1] == 1 :
           st.success('ê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")
       #elif label_1_5[0] == 1 and label_1_5[1] == 0:
            #st.success('ê³±ì˜ ê±°ë“­ì œê³±ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
       #elif label_1_5[0] == 0 and label_1_5[1] == 1:
            #st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê³±ì˜ ê±°ë“­ì œê³±ì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")     
       else:
            st.info('ê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")

if st.button('â“íŒíŠ¸ ë³´ê¸°', key='button1_1_5_2'):
    st.write('ê´„í˜¸ ì•ˆì˜ ì‹ì„ ì„¸ì œê³±í•˜ì„¸ìš”!')


st.markdown("---")
# ë¬¸í•­1-6

st.subheader("ë¬¸í•­1-6")
st.markdown("$$ \\left( {b} \\over {3}\\right)^{4} = $$")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_6')

# ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_6 = "1-6_att_sp_74"  # ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
# ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 74  # vocab size
emb = 16  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu"  # default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
# output_d ì„¤ì •
output_d_1_6 = 1  # ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

# model = RNNModel(output_d_1_1, c)  # RNNModel ì“°ëŠ”ê²½ìš°
# model = LSTMModel(output_d, c) #LSTMModel ì“°ëŠ”ê²½ìš°
model_1_6 = ATTModel(output_d_1_6, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_6.load_state_dict(torch.load("./save/"+model_name_1_6+".pt"))

# ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_6 = AutoTokenizer.from_pretrained("./save/"+model_name_1_6)  # sp tokenizer ì“°ëŠ” ê²½ìš°
# tokenizer = BertTokenizer.from_pretrained("./save/"+model_name+"-vocab.txt") #bw tokenizer ì“°ëŠ”ê²½ìš°

enc = tokenizer_1_6(response)["input_ids"]  # sp tokenizer
# enc = tokenizer.encode(response) #bw tokenizer
l = len(enc)
if l < max_len:
    pad = (max_len - l) * [0] + enc
else:
    pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1, max_len)
y = model_1_6(pad_ten)
label_1_6 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button1_1_6_1'):
    
    # outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
   st.write(response)
   if label_1_6 == 1:
       st.success('ë¶„ìˆ˜ì˜ ê±°ë“­ì œê³±ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")
   else:
       st.info('ë¶„ìˆ˜ì˜ ê±°ë“­ì œê³±ì„ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")

if st.button('â“íŒíŠ¸ ë³´ê¸°', key='button1_1_6_2'):
    st.write('ë¶„ëª¨ì™€ ë¶„ì ëª¨ë‘ ë„¤ì œê³±í•˜ì„¸ìš”!')



st.markdown("---")
#ë¬¸í•­1-7

st.subheader("ë¬¸í•­1-7")
st.markdown("$$ (2^4)^x \\times (2^2)^x=2^3 \\times 2^{3x} $$ì¼ ë•Œ, ìì—°ìˆ˜ $$x$$ì˜ ê°’ì„ êµ¬í•˜ì‹œì˜¤.")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_7')

#ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_7 = "1-7_att_sp_140" #ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
#ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 140 #vocab size
emb = 16 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu" #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
#output_d ì„¤ì •
output_d_1_7 = 3 #ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

# model = RNNModel(output_d, c) #RNNModel ì“°ëŠ”ê²½ìš°
# model = LSTMModel(output_d, c) #LSTMModel ì“°ëŠ”ê²½ìš°
model_1_7 = ATTModel(output_d_1_7, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_7.load_state_dict(torch.load("./save/"+model_name_1_7+".pt"))

#ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_7 = AutoTokenizer.from_pretrained("./save/"+model_name_1_7) #sp tokenizer ì“°ëŠ” ê²½ìš°
# tokenizer = BertTokenizer.from_pretrained("./save/"+model_name+"-vocab.txt") #bw tokenizer ì“°ëŠ”ê²½ìš°

enc = tokenizer_1_7(response)["input_ids"] #sp tokenizer
# enc = tokenizer.encode(response) #bw tokenizer
l = len(enc)
if l < max_len :
    pad = (max_len - l) * [0] + enc
else : pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1,max_len)
y = model_1_7(pad_ten)
label_1_7 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button1_7_1'):
    
    #outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
    
    st.write(response)
    if len(label_1_7) >= 3:
        if label_1_7[0] == 1 and label_1_7[1] == 1 and label_1_7[2] == 1:
            st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")   
        #elif label_1_7[0] == 1 and label_1_7[1] == 1 and label_1_7[2] == 0:
            #st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
        #elif label_1_7[0] == 1 and label_1_7[1] == 0 and label_1_7[2] == 0:
            #st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ë¥¼ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
        #elif label_1_7[0] == 0 and label_1_7[1] == 1 and label_1_7[2] == 0:
            #st.success('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
        #elif label_1_7[2] == 0 and label_1_7[2] == 0 and label_1_7[2] == 1:
            #st.success('ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
        else:
            st.info('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")

if st.button('â“íŒíŠ¸ ë³´ê¸°', key='button1_7_2'):
    st.write('ë°‘ì´ 2ë¡œ ê°™ìœ¼ë‹ˆ, ì§€ìˆ˜ë¥¼ ì •ë¦¬í•˜ì„¸ìš”!')


st.markdown("---")
#ë¬¸í•­1-8

st.subheader("ë¬¸í•­1-8")
st.markdown("ì €ì¥ ë§¤ì²´ì˜ ìš©ëŸ‰ì„ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ìœ„ë¡œ B, KB, MB ë“±ì´ ìˆê³ , 1KB=$2^{10}$B, 1MB=$2^{10}$KBì´ë‹¤. ì°¬í˜ì´ê°€ ì»´í“¨í„°ë¡œ ìš©ëŸ‰ì´ 36MBì¸ ìë£Œë¥¼ ë‚´ë ¤ë°›ìœ¼ë ¤ê³  í•œë‹¤. ì´ ì»´í“¨í„°ì—ì„œ 1ì´ˆë‹¹ ë‚´ë ¤ë°›ëŠ” ìë£Œì˜ ìš©ëŸ‰ì´ $9 \\times 2^{20}$KBì¼ ë•Œ, ì°¬í˜ì´ê°€ ìë£Œë¥¼ ëª¨ë‘ ë‚´ë ¤ë°›ëŠ” ë° ëª‡ ì´ˆê°€ ê±¸ë¦¬ëŠ”ì§€ êµ¬í•˜ì‹œì˜¤.")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_8')

#ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_8 = "1-8_lstm_sp_140" #ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
#ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 140 #vocab size
emb = 16 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu" #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
#output_d ì„¤ì •
output_d_1_8 = 5 #ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

# model = RNNModel(output_d, c) #RNNModel ì“°ëŠ”ê²½ìš°
model_1_8 = LSTMModel(output_d_1_8, c) #LSTMModel ì“°ëŠ”ê²½ìš°
# model = ATTModel(output_d, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_8.load_state_dict(torch.load("./save/"+model_name_1_8+".pt"))

#ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_8 = AutoTokenizer.from_pretrained("./save/"+model_name_1_8) #sp tokenizer ì“°ëŠ” ê²½ìš°
# tokenizer = BertTokenizer.from_pretrained("./save/"+model_name_1_8+"-vocab.txt") #bw tokenizer ì“°ëŠ”ê²½ìš°

enc = tokenizer_1_8(response)["input_ids"] #sp tokenizer
# enc = tokenizer.encode(response) #bw tokenizer
l = len(enc)
if l < max_len :
    pad = (max_len - l) * [0] + enc
else : pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1,max_len)
y = model_1_8(pad_ten)
label_1_8 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button_1_8_1'):
    #outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
    st.write(response)
    if len(label_1_8) >= 5:
        if label_1_8[0] == 1 and label_1_8[1] == 1 and label_1_8[2] == 1 and label_1_8[3] == 0 and label_1_8[4] == 0:
            st.success('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ, ë‹¨ìœ„ ë³€í™˜ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")
        elif label_1_8[0] == 0 and label_1_8[1] == 0 and label_1_8[2] == 0 and label_1_8[3] == 1 and label_1_8[4] == 1:
            st.success('ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ, ìˆ˜ì˜ ë‚˜ëˆ—ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")
        #elif label[0] == 1 and label[1] == 0 and label[2] == 1 and label[3] == 0 and label[4] == 0:
        #    st.success('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ë‹¨ìœ„ ë³€í™˜ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì–´ë³´ì„¸ìš”!', icon="â„¹ï¸")
        #elif label[0] == 0 and label[1] == 0 and label[2] == 1 and label[3] == 0 and label[4] == 0:
        #    st.success('ë‹¨ìœ„ ë³€í™˜ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ, ìˆ˜ì˜ ë‚˜ëˆ—ì…ˆì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì–´ë³´ì„¸ìš”!', icon="â„¹ï¸")       
        #elif label[0] == 0 and label[1] == 1 and label[2] == 0 and label[3] == 0 and label[4] == 0:
        #    st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ë‹¨ìœ„ ë³€í™˜, ìˆ˜ì˜ ë‚˜ëˆ—ì…ˆì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì–´ë³´ì„¸ìš”!', icon="â„¹ï¸")
        #elif label[0] == 0 and label[1] == 0 and label[2] == 0 and label[3] == 1 and label[4] == 0:
        #    st.success('ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ë‹¨ìœ„ ë³€í™˜ì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì–´ë³´ì„¸ìš”!', icon="â„¹ï¸")
        #elif label[0] == 1 and label[1] == 0 and label[2] == 0 and label[3] == 0 and label[4] == 0:
        #    st.success('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ, ë‹¨ìœ„ ë³€í™˜ì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì–´ë³´ì„¸ìš”!', icon="â„¹ï¸")
       
        else:
            st.info('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ê±°ë“­ì œê³±ì˜ ë‚˜ëˆ—ì…ˆ, ë‹¨ìœ„ ë³€í™˜, ìˆ˜ì˜ ë‚˜ëˆ—ì…ˆì„ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")

if st.button('â“íŒíŠ¸ ë³´ê¸°', key='button_1_8_2'):
    st.write('ë‹¨ìœ„ ë³€í™˜ì„ í•´ë³´ì„¸ìš”!')
